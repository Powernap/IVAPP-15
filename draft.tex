\documentclass[a4paper,twoside]{style/article}
\usepackage{epsfig}
\usepackage{subfigure}
\usepackage{calc}
\usepackage{amssymb}
\usepackage{amstext}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{multicol}
\usepackage{pslatex}
\usepackage{apalike}
\usepackage{style/SCITEPRESS}
\usepackage[small]{caption}

\subfigtopskip=0pt
\subfigcapskip=0pt
\subfigbottomskip=0pt

% My Packages and Commands ---
\usepackage[normalem]{ulem}
\usepackage{xcolor}
\usepackage[]{algorithm2e}
\usepackage[utf8]{inputenc}
\newcommand{\rem}[1]{\textcolor{red}{\sout{#1}}}
\newcommand{\add}[1]{\textcolor{blue}{\uline{#1}}}
\newcommand{\com}[1]{\textcolor{orange}{\uline{#1}}}
% /My Packages and Commands --

\begin{document}

\title{Insight Into Lumbar Back Pain  \subtitle{What the Lumbar Spine Tells About Your Life} }

\author{\authorname{Paul Klemm\sup{1}, Sylvia Glaßer\sup{1}, Kai Lawonn\sup{1} Henry Völzke\sup{2}, Katrin Hegenscheid\sup{3} and Bernhard Preim\sup{1}}
\affiliation{\sup{1}Department of Simulation and Graphics, University of Magdeburg}
\affiliation{\sup{2} Institut for Community Medicine, University of Greifswald}
\affiliation{\sup{3} Institute for Diagnostic Radiology and Neuro-Radiology, University of Greifswald}
\email{\{paul, sylvia\}@isg.cs.uni-magdeburg.de, \{katrin.hegenscheid, voelzke\}@uni-greifswald.de}
}

\keywords{Epidemiology, Interactive Visual Analysis}

% \abstract{The abstract should summarize the contents of the paper and should contain at least 70 and at most 200 words.}
\abstract{ 
The goal of epidemiology is to provide insight into disease causations.
%%
Hence, subject groups (cohorts) are analyzed to correlate the subjects' varying lifestyles and medical properties with diseases.
%%
Recently, these cohort studies comprise medical image data as well.
%%
We assess the predictive quality of image-derived variables for lower back pain.
%%
The evaluation is embedded in an interactive visual analysis (IVA) framework that is based on 2,540 segmented lumbar spine data sets.
%%
The segmentation results are evaluated and quantified by employing shape-describing variables, such as the spine canal course, its curvature and torsion.
%%
We analyze the predictive power of shape-describing variables for non-image variables, e.g., pain indicators.
%%
Therefore, we automatically extract a decision tree classifier for each non-image variable.
%%
Furthermore, we provide an IVA technique to compare the classifiers with interactive scatterplot visualizations.
%%
As a first result, we conclude that image-based variables are only sufficient for classification of lifestyle factors.
%%
A correlation between lumbar spine shape and lower back pain disease was not existent in the automatically trained classifiers.
%%
However, the presented approach is a valuable extension for the IVA of epidemiological data.
%%
Hence, correlations between non-image parameters were successfully detected and characterized.
}

\onecolumn \maketitle \normalsize \vfill

\section{\uppercase{Introduction}}
\label{sec:Introduction}
%%Epidemiology is the study of causation of diseases.
Epidemiology is the study of dissemination, causes and results of health-related states and events.
%%
For this purpose, large population studies, such as the \emph{Study of Health in Pomerania} (SHIP) [??] gather as much information as possible about participants to be assessed towards different diseases.
%%
These information are used to determine risk factors for diseases, help people to improve their lifestyle and their health or to support diagnosis of widespread diseases.
%%
Epidemiological research is strongly hypothesis-driven.
%%
More precisely, observations made by clinicians are translated into hypotheses, which are then statistically evaluated using data variables from epidemiological studies.
%%
As a result, the hypothesis will be accepted or rejected.
%%

%For epidemiological research, cohort studies are acquired.
For epidemiological research, cohort studies are carried out.
%%
Since recently, these studies often comprise medical image data, e.g., tomographic image data sets, as well as general patient-specific attributes, such as gender, age and weight.
%%
Back pain is one of the most frequent diseases in the western civilization. 
%%
Epidemiological analysis of back pain aims to characterize the disease by determining risk factors.
%Many epidemiological-motivated approaches aim at improved characterization of this disease with respect to patient-specific attributes.
%Since back pain is one of the most frequent diseases in the western civilization, many epidemiological-motivated approaches aim at improved characterization of this disease with respect to patient-specific attributes.
%%
Although the shape and constitution of the spine, especially the lumbar spine, plays an important role for the presence of back pain, no automatic classification approach to characterize back pain based on lumbar back spine attributes has been established.
%%
Furthermore, previous analyses mainly focused on a single parameter or a small subset of parameters [Quelle].
%%

In this paper, we present a thorough analysis of the image-derived data from lumbar back spine datasets and analyze their discriminating power for different characteristics of the disease.
%%
For this purpose, we combine data mining algorithms with data visualization techniques.
%%
%Then, interactive visual analysis provides insight into the quality of the image-derived data as well as their potential for possible back pain risk factors.
Then, interactive visual analysis provides insight into the quality of the image-derived data as well as their potential for being back pain risk factors.
%%
\com{Da in der Auflistung oefter vom IVA-Framework die Rede ist: Wollen wir hierzu noch was schreiben, z.B. dass das im VIS-Paper definiert wurde und was wir darunter verstehen; sowie dass diese Arbeit als Erweiterung dieses Frameworks gedacht ist?}

Our contributions are:
\begin{itemize}
\item An IVA-framework for back pain analysis based on image-derived variables of 2,240 subjects \com{Ist diskutabel, so richtig interaktiv ist es nicht. IVA wurde auch noch nicht vorher definiert.}
%%
\item The identification and evaluation of lumbar spine shape properties for back pain diagnosis
%%
\item Detection of correlations between image-based and socio-demographic as well as medical parameters for an improved hypothesis generation
%%
\item Identification of the most important variables via data mining methods (including a novel semi-quantitative evaluation concept) embedded in our IVA-framework \com{Wieder: IVA wurde noch nicht definiert}
%%
\end{itemize}
%% ---------------------------------------------
\section{\uppercase{Epidemiological Background}}
\label{sec:EpidemiologicalBackground}
%%
\noindent Epidemiological reasoning relies on a strict statistically driven workflow \cite{Fletcher}:
%%
\begin{itemize}
%%
	\item Physicians formulate hypotheses based on observations made in their clinical practice.
%%
	\item To assess a hypothesis, epidemiologists compile a list of variables depicting it.
%%
	\item Statistical methods, such as regression analysis, assess the association of selected variables with the investigated disease.
%%
\end{itemize}
%%
Mutually dependent variables make this analysis challenging.
%%
Many diseases, such as different cancer types, are more likely with increasing age.
%%
When for example analyzing influences of nutrition to prostate cancer, the results need to be age-normalized.
%%
Age acts as a \emph{confounder} for prostate cancer.
%%
%These \emph{confounding} variables are often hard to find.
%%
Statistical correlation does not imply causation--epidemiologists need to assess the medical soundness of the statistical results.
%%------------------------------
\subsection{Epidemiological Data}
Epidemiological data originates from a wide range of studies.
%%
The study type depends on the condition of interest.
%%
Most common are case-control studies, analyzing one specific disease and its influences on the human body.
%%
We focus on data from large scale cohort studies.
%%
These studies aim to collect as much data as possible for each subject.
%%
As a result, these data can be analyzed regarding many diseases and conditions.
%%

Epidemiological data is heterogenous and incomplete.
%%
For example women-specific questions or data about a disease treatment only subjects suffering from this condition.
%%
Statistical analysis has to take missing data into account.
%%

Epidemiologists acquire data using a wide range of techniques, such as medical examinations, self reported questionnaires or genetic examinations.
%%
This yields a heterogenous information space.
%%
To compare these data, information reduction techniques are applied.
%%
For example, continuous data, such as age is often discretized into age-bins.
%%
Every information reduction can introduce a bias to the data, since it reflects an assumption about the data.
%%
Using age to divide subjects into \emph{young} and \emph{old} categories can distort statistical results.
%%
This distortion is reduced with increasing number of discretization steps.
%%

Modern cohort studies often comprise medical image data.
%%
These data are hard to analyze.
%%
Individual diagnosis or manual segmentation of each body structure by an radiologists is tedious, costly and comprises little reproducibility.
%%
Segmentation algorithms are not generally available and need to be custom-made for each body structure.
%%
Segmentation data is usually analyzed by abstracting it into key figures, such as diameters or distances.
%%
These numeric values can be compared with non-image variables to retrieve correlations.
%%--------------------------------
\subsection{Lower Back Pain}
%%
The lower (\emph{lumbar}) spine is the most stressed spine part.
%%
Lower back pain is one of the most frequent diseases in the western civilization.
%%
Epidemiologists assume associations between lumbar back pain and lifestyle factors.
%%
These include nutrition, sporting activities and body posture combined with physical stress at work.
%%
The exact causes as well as particularly vulnerable risk groups are not known.
%%
Potential \emph{confounding} effects are also subject of current research.
%%

Epidemiologists want to characterize the healthy aging process of the spine.
%%
To achieve this, they have to analyze the lumbar spine shape as well as the mentioned lifestyle factors.
%% -------------------------------
\section{\uppercase{Related Work}}
\label{sec:RelatedWork}
%%
\paragraph{Visual Analysis of Image and non-Image Data}
%%
Klemm et al. propose an extension to the previously described epidemiological workflow using \emph{Interactive Visual Analysis} (IVA) \cite{Klemm2014VIS}.
%%
The workflow consists of an iterative sequence of \emph{group selection}, \emph{variable selection} and \emph{visualization}.
%%
It aims to trigger \emph{hypothesis generation} by providing visualizations able to concurrently analyze multiple heterogenous variables at once using correlation measures.
%%
We incorporate the IVA approach by concurrently displaying complex relationships between variables using decision trees.
%%
Steenwijk et al. propose a coordinated linked view system for both image-related and non-image data \cite{Steenwijk}.
%%
It incorporates multiple plot types, such as scatter plots, parallel coordinates and time plots with brushing and linking facilities.
%%
Similar to our work, they quantify image data and project it into the non-image data information space.
%%
Turkay et al. follow a similar approach by deriving descriptive data metrics from image data \cite{Turkay}.
%%
Their proposed \emph{deviation plot} shows distribution-specific measures of a variable, such as skewness or inter-quantile-range, making variables comparable.
%%
This approach aims to trigger \emph{hypothesis generation} by outlining tendencies between these variables.
%%
\paragraph{Visual Analysis of Heterogenous Non-Image Data.}
%%
Zhang et al. analyze subject groups in a web-based linked view system \cite{Zhang}.
%%
The resulting decision rules aim to categorize new subjects as they are added to the data.
%%
They define a cohort as parameter-divided subject group, differing from the epidemiological understanding of the term.
%%
The paper lacks details about handling of missing data, the definition of similarity or which statistical measures are applied.
%%
Generalized Pairs Plots (\texttt{GPLOM'S}) visualize heterogenous variables in a plot matrix \cite{GPLOMS,Francois}.
%%
The plot depends on the type of variables, which are pairwise visualized.
%%
The plot matrix is well suited for an overview visualization, but takes up much screen space and is therefore only suitable for few variables at once (see Fig.~\ref{fig:image-parameter-range}).
%%
Dai and Gahegan defined a \emph{Concept Map}, linking cancer-associated features by incorporating choropleth maps with bar charts, parallel coordinates and scatter plots with regression lines \cite{Dai}.
%%
The \emph{Concept Map} is iteratively refined using primarily the underlying geographical data.
%%
%Our work, however, does not contain geographical information of any kind.
%%----------------------------
\paragraph{Decision Rule Driven Analysis of Medical Data.}
Related work in this field often focuses on clinical diagnosis.
%%
Closest to ours is the work of Gla{\ss}er \cite{Glasser2013} and Niemann et al. \cite{Niemann2014}.
%%
Gla{\ss}er et al. use variables derived from DCE-MRI data capturing the perfusion in the tumorous tissue \cite{Glasser2013}.
%%
They aim to classify breast tumors.
%%
The extracted variables train a decision-tree classifier, concluding that the extracted features alone are not sufficient for tumor type classification.
%%
Niemann et al. assess hepatic steatosis (fatty liver disease) risk factors using decision trees \cite{Niemann2014}.
%%
They presented an interactive data mining tool, which can analyze association rules and highlight interesting relations, which may trigger new hypothesis about the data.
%%
We combine ideas of both papers by validating the significance of image-derived parameter aiming to derive new relationships by training decision trees to explain target variables.
%%----------------------------

Pinhero et al. applied association rule mining to create high-confidence decision rules based on variables such as age, gender and geographic location about the mortality rate in liver cancer data \cite{Pinheiro}.
%%
Decision rules are easily readable and are well suited for classifying medical data. \com{Das frueher erwaehnen}
%%
The results can be easily communicated to domain experts with little knowledge about the algorithm behind the results.
%%
Once these rules, get too complex, analyzing these decision rules becomes complex.
%%
Sekhavat and Hoeber propose an interactive visualization technique for decision trees, where all decisions are displayed in a heat map \cite{Sekhavat}.
%%
The visualization translates the decision tree into a heat map, where each cell represents the connectivity between an initial value and an target value.
%%
The resulting interactive visualization is well suited for analyzing single, but not multiple decision trees.
%%
\paragraph{SHIP Data Analysis.}
Klemm et al. analyzed the lumbar spine variability of of 490 \texttt{SHIP-2} subjects \cite{Klemm2013VMV}.
%%
They incorporate hierarchical agglomerative clustering to derive shape groups, yielding several groups of average shape and several outlier cluster.
%%
The extracted lumbar spine shape was correlated with subject size.
%%
The data extraction process is based on the detection algorithm and lumbar spine canal extraction presented in this paper.
%%
Clustering techniques applied to non-image data are strongly dependent on the chosen variables and distance measures.
%%
%Klemm et al. found \texttt{k-Prototypes} and \texttt{DBSCAN} appropriate for this task \cite{Klemm2014BVM}.
%%
\\\\
Unique for our work is the combination of an IVA-approach by observing interesting feature relations in context of image-derived features using multiple decision trees for one visualization.
%%
We abstract the decision tree results similar to \cite{Turkay}, making them comparable in an overview visualization.
%%
\section{The Lumbar Spine Data Set}
\label{sec:MaterialsAndMethod}
%%
\noindent Our approach allows to analyze many variables simultaneously.
%%
Therefore, epidemiologists compiled the data set with a with a wide range of variables possibly correlating with lumbar back pain.
%%
The data set comprises of 6.753 subjects from two cohorts (4.420 from \texttt{SHIP-Trend-0} and 2.333 from \texttt{SHIP-2}).
%%
%It is an active research area to determine these correlations.
%%

%%
\subsection{Non-Image Data}
%\com{Analysis Using Heterogeneous Correlation}
The variables range from somatometric variables describing body measures to medical examinations, such as laboratory tests as well as lifestyle factors as sporting activity or nutrition. \com{Ein paar Details hierzu noch - Datentyp, missing data, aufeinander aufbauende parameter}

\subsection{Image Data}
\begin{figure}[!h]
  %\vspace{-0.2cm}
  \centering
  \includegraphics[width=0.5\textwidth]{figures/centerline}
  \caption{
	(a) left: Tetrahedron-based finite element model (FEM) of the lumbar spine, capturing the L1-L5 vertebrae as well as the lumbar spine canal.
	%%
	(a) right: FEM aligned to a MRI data set.
	%%
	The purple dashed line represents the centerline, describing the lumbar spine canal with 92 points.
	%%
	(b) Using the Frenet formulas, we extract the weighted sum of curvature and torsion for all 92 points (white dashes).
	%%
	The curvature angle ($\alpha$) is calculated using the top, bottom and middle point.
	%%
	We also extracted the variables for each projection axis to assess their information gain.
	%(b) Using the Frenet formulas, we extract the curvature, torsion and the curvature angle from the lumbar spine canal center line.
	}
  \label{fig:centerline}
\end{figure}
Four trained radiology technicians acquired the medical image data for each subject in a standardized way using a 1.5~Tesla MRI scanner (Magnetom Avanto; Siemens Medical Solutions, Erlangen, Germany).
%%
The spine protocol consisted of a sagittal T1-weighted turbo-spin-echo sequence ($1.1\times1.1\times4.0~mm$ voxels) and a sagittal T2-weighted turbo-spin-echo sequence ($1.1\times1.1\times4.0~mm$ voxels) \cite{Hegenscheid2013}.
%%

A hierarchical finite element method was used to detect the lumbar spine in the MRI data \cite{Rak2013}.
%%
The tetrahedron-based finite element model is initialized using three user-placed landmarks.
%%
A click on the L3 vertebra center initialized the model, two clicks on the top and bottom of the vertebra describes an initial height estimation.
%%
The registered model captures information about the lumbar spine canal shape and the position of the L1-L5 vertebrae \cite{Klemm2013VMV} (Fig.~\ref{fig:centerline}~a).
%%
The detection fails for several subjects due imprecise initialization, imaging artifacts or strongly deformed spines.
%%
$2,540$ lumbar spine models were obtained and constitute the foundation of this work.
%%
%%
% \com{From VIS'14 Paper}
% The lumbar spine was detected in the image data using a hierarchical finite element method by Rak et al. [32].
% %%
% This semiautomatic method requires the user to initialize the tetrahedron-based finite element models (FEM) with a click on the L3 vertebra.
% %%
% Two user-defined landmarks on the top and bottom of the L3 vertebra describe an initial model height estimation.
% %%
% The model uses a weighted sum of T1 and T2-weighted MR images to detect the lumbar spine shape.
% %%
% Once registered, it captures information about the shape of the lumbar spine canal as well as the position of the L1-L5 vertebrae [21].
% %%
% Due to incorrect initialization, strongly deformed spines, contrast differences and artifacts, the model was not able to detect lumbar spines for all subjects.
% %%
% We obtained and worked with 2,540 tetrahedron models of the lumbar spine.
% %%
% For clustering, we extracted the centerline of the lumbar spine canal, which captures information about lordosis and scoliosis (the medical terms for spine curvature) [21].
% %%

We have to assess the model accuracy to extract key figures from it.
%%
The detection model depicts the vertebrae positions, but lacks detailed information about their volume.
%%
It captures reliable information about spine canal curvature.
%%
In a previous work (\cite{Klemm2013VMV}), we extracted a centerline representation of the lumbar spine canal from the detection model (Fig.~\ref{fig:centerline}~a).
%%
Using the Frenet formulas, we calculated the following metrics from the model (Fig.~\ref{fig:centerline}~b) \cite{Frenet}:
%%
%Thus, we extracted the following metrics from the model:
%%
%\paragraph{Curvature}
\begin{itemize}
	% \item The curvature of the centerline is calculated using the summed mean curvature between adjacent points:
% %%
% $\sum \frac{curvature_i}{curvature_all}$.
	\item \emph{Curvature} is calculated as weighted sum of curvature between all adjacent points describing the centerline: $\sum \frac{curvature_i}{curvature_{all}}$.
%%
	\item \emph{Torsion} (deviation of a curve from its current course) is calculated as weighted sum of torsion between all adjacent points describing the centerline: $\sum \frac{torsion_i}{torsion_{all}}$.
	\item \emph{Curvature angle $\alpha$} is defined by the middle point of the spine canal centerline as \emph{vertex} and the line between middle point and top/bottom point as \emph{sides}.
%%
\end{itemize}
%%
These figures are also extracted in the sagittal, coronal and transversal projection of the model.
%%
We assess the information gain of each dimension using these projections.
%%
This gives us a total of 9 image-derived parameters.

%\subsection{Creating a Decision Tree using C5.0}
%\com{C4.5 Algorithm for creating decision trees; }

%\subsection{Parameter Assessment}
%Based on first results

\section{\uppercase{Experiments}}
\label{sec:Experiments}
\begin{figure}[!h]
  %\vspace{-0.2cm}
  \centering
  \includegraphics[width=0.5\textwidth]{figures/age-gender}
  \caption{
	%%
	Correlation of age and gender regarding the lumbar spine size.
	%%
	The bar chart shows subjects divided into four different age groups (x-axis) and their subject number (y-axis).
	%%
	Each bar contains the mean lumbar spine of the respective group.
	%%
	The shape color encodes the distance to the overall male (top chart) or female (bottom chart) mean shape.
	%%
	The dark gray share of each bar encodes the portion of male (top chart) or female (bottom chart) subjects.
	%%
	Women have a higher live expectance than men, hence their higher share in the old age group.
	%%
	Also, women are on average smaller than men, hence the larger shape similarity with older subjects.
	%%
	Due to bone erosion, older people are also smaller on average.
	}
  \label{fig:age-gender}
\end{figure}
\noindent Spine shape is confounded by several somatometric variables.
%%
Larger people have also a longer spine and its shape is more straight.
%%
Since men are on average taller than women and people of old age shrink due to bone erosion, gender and age are also confounders (Fig.~\ref{fig:age-gender}).
%%
Large body weight increases the spine load, resulting in a bend shape.
%%
All these variables need to be taken into account, when correlating spine curvature and torsion with non-image parameter.
%%
Since the gender confounder mainly encodes body-size, we decided to divide subjects into body-size groups.
%%
To avoid small outlier groups, epidemiologists recommend using quartiles to discretize metric variables \cite{Klemm2014VIS}.
\subsection{Preliminary Results}
\begin{figure*}[htb]
  %\vspace{-0.2cm}
  \centering
  \includegraphics[width=1.0\textwidth]{figures/image-parameter-range}
  \caption{%%
A generalized pairs plot of all image-derived variables colored by presence or absence of back pain.
%%
Pairwise combinations of image-derived variables are visualized using scatter plots left of the matrix diagonal and their correlation with back pain is denoted right of the matrix diagonal.
%%
The box plots (left) and histograms (bottom) display the distribution of each image-variable encoded with back pain.
%%
No correlation with back pain are present can be seen in this plot.
}
  \label{fig:image-parameter-range}
\end{figure*}
%%
\noindent As first experiment we correlated the shape parameter with the binary back pain indicator using \texttt{GPLOM's} \cite{GPLOMS}.
%%
%Pairs plots visualize continuous and categorical variables pairwise in a matrix view.
%%
%Scatterplots display pairs of continuous variables, bar charts for continuous variable as a function of a categorical variable and box plots pairs of categorical variables.
%%
Since our image-derived variables are metric, their pairwise combinations are visualized using scatterplots.
%%
The combination of the image variables with back pain is visualized as histogram at the left side of the matrix and as box plot on the right side.
%%
Figure~\ref{fig:image-parameter-range} (right) shows the range of each variable as box plot.
%%
The projections to the transversal planes attract attention as they have many outliers.
%%
We conclude that curvature is not as reliable on the transversal plane as it is on the other planes.
%%--------------------------------
\subsubsection{Correlation Matrix}
We calculated an association matrix to assess correlations between the image parameters.
%%
The pearson correlation coefficients between the numeric variables are depicted right of the matrix diagonal in Figure~\ref{fig:image-parameter-range}.
%%
\emph{Curvature}, \emph{curvature angle} and \emph{torsion} correlate strongly with their planar projections.
%%
Also the mean curvature and the curvature angle correlate by a factor of $-0.89$.
%%
%Torsion and curvature/curvature angle do not correlate.
Torsion does not correlate with any other image-derived variable.
%%--------------------------------------------------------
\subsubsection{Correlation of Image Parameters With Back Pain}
Figure~\ref{fig:image-parameter-range} shows the distribution of all image-parameters \add{as generalized pairs plot}.
%%
\rem{We created a generalized pairs plot for subject groups derived by dividing them into quantile groups of body-size.}
%%
No statistically significant correlation could be observed through all subject groups.
%%
The box plots show no difference between subjects with and without back pain.

\subsubsection{Assessing the Information Gain Using the PCA}
%%
To determine the information gain per image-derived variables, we calculated a PCA and compared the loadings per dimension.
%%
The first three principal components explain 75\% of the variance in the image-derived variables.
%%
The first principal component explains 47\% of the variance and weights primarily \emph{mean curvature}, \emph{curvature sagittal}, \emph{curvature angle} and \emph{curvature angle sagittal}.
%%
The second component, adding 16\% of the variance, weigths  \emph{curvature coronal} and \emph{curvature angle coronal}.
%%
The third component explains 12\% of the variance and weights \emph{torsion} and \emph{curvature transverse}.
%%
This supports our prior conclusion about the low information gain of the transverse planes.
%%
\emph{Torsion} also adds little variance to the information space.
%% ------------------------------------------
\subsubsection{Heterogenous Correlations}
%%
We then expanded our focus on correlations of image-derived parameters with all other non-image variables.
%%
We applied a heterogenous correlation technique to derive correlations between all variables is the data set.
%%
The method uses the following correlation metrics for the different type combination:
%%
\begin{itemize}
%%
\item \emph{Pearson product-moment} for two continuous variables, 
\item \emph{Polyserial} correlation for one continuous and one categorical variable, and
\item \emph{Polychoric} correlations for two categorical variables.
\end{itemize}
\com{TODO: Abbildung einer Korrelationsmatrix? Waere sehr gross!}
%%
All correlation values are scaled between \texttt{0 - no correlation} and \texttt{1 - identical}.
%%
Some variables are too sparse for calculating correlations, for example \emph{treatment of diabetes}, or \emph{medication against high blood pressure}.
%%
We display the resulting \emph{contingency matrix} using a heat map, mapping correlation values to color brightness with white for 0 and dark blue for 1 \cite{Klemm2014VIS}.
%%
We calculated the contingency matrix for all size groups and looked for correlations between image- and non-image derived variables.
%%
The resulting contingency matrices are available as supplementary material and show no strong correlation with any of the parameter.
%%
Only weak correlations could be found for \emph{Mean Curvature} with \emph{gender} (0.42), \emph{body size} (0.39) and \emph{number of born children} (0.29).
%%
One surprising result was the small correlation with \emph{torsion}, which correlated with almost no variables (p values between 0 and 0.05) and \emph{parkinson} (0.24).
%%

These observations brought us to the conclusion to incorporate more sophisticated data mining techniques to assess the influence of the image-derived parameters.

% \subsubsection{Diese Themen hier unterbringen}
% \begin{itemize}
% 	\item Direkter Vergleich
% 	\item Verteilung des Means
% 	\item Korrelationsmatrix
% 	\item PCA
% \end{itemize}
% Weil das nicht ausreichend war, haben wir einen C5.0 Baum erstellt, um alle potentiellen Zusammenhänge zwischen bildbezogenen und Nichtbildbezogenen Parametern herzustellen - Was kann man mit den Bilddaten erklären und was nicht?
%
% HetCor hier noch mit unterbringen. Damit kann man eine Korrelationsmatrix unabhängig vom Datentyp berechnen, um eine große Korrellationsmatrix zu erhalten (Supplementary Material). Hier können die Einträge in den Zeilen der Bildparameter angeschaut werden, um zu schauen, ob man eine Korrellation mit bestimmten Parametern finden kann! Das müsste auch wieder für alle Größengruppen passieren! (https://stats.stackexchange.com/questions/101016/pca-and-component-scores-based-on-a-mix-of-continuous-binary-and-categorical-va)
% Creating a Decision Tree using C5.0

%\com{C4.5 Algorithm for creating decision trees; }

\section{\uppercase{Evaluation of Decision Trees}}
\label{sec:DecisionTrees}
%%
\noindent As described before, correlation coefficients fail to infer back pain status based on lumbar spine canal curvature and torsion.
%%
We rely on predictive classification trained to obtain a complex rule set on how combinations of the image-parameter explain non-image variables.
%%
Decision trees are a popular classification method in data mining for creating predictive models.
%%
Leafs of a decision tree represent class labels, branches represent feature conjunctions leading to the class labels.
%%
Decision trees are easy to understand and to read.
%%
They work with numerical as well as categorical data.
%%
This allows epidemiologists to interpret the results without having deep knowledge about the algorithm creating the tree.
%%
Readability is only granted for small trees, complex structures with many branches are not desirable.
%%
Too many branches also impose overfitting to the data.
\com{Quelle Decision Tree}

\subsection{The C4.5/C5.0 Algorithm}
Using a trained data set, the C4.5 algorithm builds decision trees based on information entropy.
%%
Such a calculation requires a numeric or categorical target variable.
%%
The algorithm then tries to find a decision tree, which divides the samples using the input variables just like the target variables.
%%
This means, that every node in the tree represents the attribute which splits the data most efficiently into the target subset.
%%
The pseudocode for the algorithm is defined in Algorithm~\ref{alg:c4.5} \cite{C4.5Algorithm}.
\begin{algorithm}[]
 Check for base cases\;
 \For{each attribute $a$}{
  Find the normalized information gain ratio from splitting on $a$\;
 }
 Let $a_{best}$ be the attribute with the highest normalized information gain\;
 Create a decision node that splits on $a_{best}$\;
 Recurse on the sublists obtained by splitting on $a_{best}$, and add those nodes as children of node\;
 \caption{Building a decision tree using the C4.5 Algorithm}
 \label{alg:c4.5}
\end{algorithm}
C5.0 is developed to produce smaller decision trees than C4.5 and improve the execution time.
%%
We use the \texttt{R} implementation of C5.0 \cite{c5.0lassification}.
%%
% \begin{enumerate}
% %%
% \item Check for base cases
% %%
% \item For each attribute $a$
% %%
% \begin{enumerate}
% %%
% \item Find the normalized information gain ratio from splitting on $a$
% %%
% \end{enumerate}
% %%
% \item Let $a_{best}$ be the attribute with the highest normalized information gain
% %%
% \item Create a decision node that splits on $a_{best}$
% %%
% \item Recurse on the sublists obtained by splitting on $a_{best}$, and add those nodes as children of node
% %%
% \end{enumerate}
%%
Categorical attributes with more levels are biased with more information gain in a decision tree \cite{deng2011bias}.
%%
Creating dummy variables bypasses this problem.
%%

The actual use for the resulting tree is the classification of new observations (subjects).
%%
Yet, we are interested in the decision rules and the classification accuracy.

\subsection{Interactive Display of Decision Trees}
We have to create a decision tree for every non-image variable to analyze which one can be explained by image-derived variables.
%%
Since we have 134 non-image variables, the calculation yields a corresponding number of trees.
%%
Dividing the subjects into four groups using body size, the number increases to 402 trees.
%%
%To make the results cognitive feasible, we have to abstract the results of the classification.
We have to abstract the results of the classification to keep the mental effort of interpreting the data low.
%%------------
\subsubsection{Visualization of Classification Results}
\label{subsec:VisualizationOfClassificationResults}
%%
%We follow the visual information-seeking mantra and want to provide an overview first, then details-on-demand \cite{shneiderman1996}.
We follow the Visual Analytics mantra by analyzing first, show the important and analyze further \cite{Keim}.
%%
A first analysis step was performed by applying the classification algorithm to the data.
%%
The optimal classification uses a few rules to precisely characterize the target variable.
%%
Therefore, we are interested in \emph{small trees} with a \emph{low classification error rate}.
%%
The two measures form the axis for a \emph{scatter plot} of the classification results.

\paragraph{The Error Term. }
Normally the error rate for a classification is calculated with $error = \frac{classifiedCorrectly_{n}} {n}$ where $n$ is the number of subjects.
%%
The metric usually works well for variables with uniform distribution.
%%
It distorts the result for other distribution types.
%%
If for example a variable indicating a disease is negative for 90\% of the subjects and the classifier simply assigns all subjects to \emph{not ill} the error metric would yield an error of 10\%, even though it is very bad.
%%
Our error term therefore incorporates the discriminative power of each manifestation and is denoted as follows:
%%
%Therefore the discriminative power of each dimension in the equation
%error = 1 - \frac{\[ \sum_{m=0}^M \] \frac{M_{classifiedCorrectly}}{M_all}}{number of dimensions}
\begin{equation}
error = 1 - \frac{\sum_{m=0}^M \frac{classifiedCorrectly_{m}}{all_{m}}}{number_{dimensions}}
\end{equation}
$M$ represents the set of manifestation of each variable.
%%
The error is scaled to denote perfect classification with 0 and 1 is equal to random selection.
% The error rate has to be judged depending on the number of classes of the target variable.
% %%
% An error rate of 50\% for a target variable with two manifestations makes the classifier equal to throwing a coin.
% %%
% The same error rate is acceptable a target variable with more than two manifestations.
% %%
% Picking a value for a variable of four manifestations with an error rate of 50\% is better than the random selection (error rate of 75\%).
% %%
% The following scales the error rate so that 0 denotes perfect classification and 1 is equal to random selection.
% %%
% \begin{equation}
% error_{normalized} = \frac{error}{100 - \frac{100}{class number}}
% \end{equation}
%%
%%
We consider a result rated below $0.25$ a good classification.
%%
It allows for comparability of error rates between variables with different manifestation count.

\paragraph{Attribute Mapping}
The scatter plot axis are defined by tree size and the previously described error metric.
%%
This allows us to visualize a multitude of classification results in one plot.
%%
If we for example classify and compare the same variables for different subject groups, for example male and female subjects.
%%
We can support this by color coding the data points according to group affiliation.

Many follow-up variables are sparse, such as \emph{medication of diabetes} or \emph{reason of early retirement}.
%%
The classification algorithm may produce higher accuracy for variables with less subjects due to the small sample size.
%%
This makes these results less reliable.
%%
We removed variables with less than 100 subjects, since they have too few subjects to be statistically significant.
%%
Furthermore, we map the number of subjects associated with a variable to point diameter in the scatter plot.
%%
This allows to instantly assess the reliability of the result.
%%

We apply a square root scale for the tree size axis to highlight data points with few decision rules.
%%
Outlier results with very large decision trees would otherwise distort the resulting plot.
%%

%\com{ToDo: SQRT Skalierung der Treesize-Dimension, da hauptsaechlich geringe Groessen von interesse sind, ausreisser aber diesen Bereich schwer durchschaubar machen}
% %%
%
% %%
% Abstracting the classification results into two continuos variables allows us to visualize the result of 134 classifications in one scatter plot.
% %%
% By mapping the group affiliation (in our case body-size) to color or shape, we can even plot all 402 results in a single visualization (Fig.~\ref{fig:decision-tree} a).
%%
\subsubsection{Dummy Variables}
Dummy variables convert a categorical variable with multiple manifestations into several binary variables.
%%
Each binary variables encodes the presence of a manifestation.
%%
For example, a pain indicator variable ranging from \emph{1 - no pain} to \emph{4 - large pain} is subdivided into four binary variables (\emph{No pain - Yes/No} to \emph{Large Pain - Yes/no}).
%%
One subject can only have one of these variables set to true.
%%
This is useful for our classification, because it allows to determine which manifestation of a variable can be described best using the image data parameter.
%%\com{ToDo: Dummy-Variables}
%%------------
\subsubsection{Interaction With the Visualization}
%%
The described visualization provides a good overview over the classification results.
%%
We still want to be able to display \emph{details-on-demand} \cite{shneiderman1996} and examine a decision tree in detail.
%%
This is realized by clicking on an entry on the visualization, which then displays the corresponding decision tree in detail.
%%
This allows for sequentially analyzing the classifications.
%%------------
\subsubsection{Implementation}
All analysis are carried out using \texttt{R}, a widely used programming language for statistical calculations and visualizations.
%%
The interactive visualizations are realized using the \texttt{ggvis}\footnote{GGVIS Footnote} package.
%%
As opposed to the standard \texttt{R} plots, \texttt{ggvis} allows to adjust visualization parameters using UI controls, such as sliders.
%%
In order to make the train of thought comprehensible, we used \texttt{RMarkdown}, which allows to create reports by combining \texttt{R} with the \texttt{Markdown} syntax.
%%
We used \texttt{R Shiny}\footnote{R Shiny footnote} to make the report available as dynamic web application.
%%
It allows to combine both the ability to create comprehensible reports as well as UI-controls, to adjust visible data and parameters in the plot to allow the viewer to analyze the data.
%%
Furthermore, calculations based on a prior data selection can be redone within the report.
%We implemented our application as web based prototype using \texttt{R Shiny}\footnote{R Shiny footnote} in combination with \texttt{RMarkdown}.
%%
%The package combines the power of \texttt{R} with advantages of web-based applications.
%%
The web-based approach allows us to quickly exchange results with our collaborating epidemiological partners.
%%
They can use the technique without installing any software.
%%
Exchanging the prototype becomes as easy as exchanging a hyperlink.
%%---------
\subsection{Results}
\begin{figure*}[p!]
  %\vspace{-0.2cm}
  \centering
  \includegraphics[width=0.95\textwidth]{figures/results}
  \caption{
%%
Scatterplot visualization of all C5.0 classification results.
%%
The x-axis shows the number of decisions of the underlying model, the y-axis the classification error rate (see Section~\ref{subsec:VisualizationOfClassificationResults}).
%%
The left scatterplot shows the results for all variables, either metrics expressed via their quantiles, or categorical.
%%
The right scatterplot displays the dummy variables derived from the original variables.
%%
Group affiliation of a data point is color coded:
%%
no group (a), subdivision into \emph{male and female subjects} (b), quartiles of \emph{age} (c) and quartiles of \emph{body size} (d).
%%
%(a) displays all subjects, (b) is divided into male and female subjects, (c) is categorized into quantiles of age and (d) shows the classification of subjects divided by quantiles of body size.
%%
The number of subjects represented in a variable is denoted using the dot diameter.
%%
We only display variables with an error rate below $0.5$, results above this threshold are inaccurate.
%%
A interactive versions of the plot (see supplemental material) makes all data points clickable, showing the corresponding decision tree in a tool tip.
%%
}
  \label{fig:results}
\end{figure*}
We ran the analysis using different subject groups:
\begin{enumerate}
	%%
	\item All subjects,
	%%
	\item subdivision into \emph{male} and \emph{female},
	%%
	\item subdivision into \emph{age quantiles}, yielding the groups (21, 43.8] (43.8, 54] (54, 64] (64, 90],
	%%
	\item subdivision into \emph{size quantiles}, yielding the groups (139, 164], (164, 171], (171, 177], (177, 202].
	%%
\end{enumerate}
We plotted each group twice.
%%
The first plot shows all original variables.
%%
The second plot shows all categorical variables transformed into dichotomous dummy variables.

\subsubsection{All Variables}
%%
The vast majority of parameters can not be described well using the classifier.
%%
This is reflected in the large amount of variables classified with an error rate above $0.6$.
%%
%The first impression of the resulting scatter plots quickly shows a very high amount of variables above an error rate of $0.6$.
%%

% None of the pain indicators can be reliably described using the image-based parameter.
None of the pain indicators can be described reliably using the image-based parameters.
%%
The only variable reliably classified in this group is gender. % with an error rate of 31.5\% using a decision tree of seven rules.
%
It can be discriminated with an error rate of $0.31$ using 7 rules and incorporates only curvature and curvature angle variables.
%%
The distinctness lies in the average difference in body size between male and female subjects.
%
%It mostly incorporates \emph{mean curvature}, \emph{sagittal curvature angle} und sagittal \emph{mean curvature}.
%The perfect categorization of the \emph{dialysis} parameter was conspicuous.
%%
%This is due to the subject distribution among the manifestation.
%%
%Only two subjects receive a dialysis.
%%
%The good discrimination is not meaningful.
%%
\emph{Medication for high blood pressure} is classified for 1,058 subjects with an error rate of $0.47$ solely based on coronal mean curvature.
%%
%1,058 subjects are classified with an error rate of $0,47$ solely based on coronal mean curvature.
%%
Almost all subjects who are medicated ($796/1,058$) were correctly classified, the vast majority of non-medicated subjects ($262/1,058$) are false-positive classified.
%%
Therefore the classifier is not as useful.
%%This is however due to the high amount of people, who are medicated (68\%) and who are almost all correctly class
%%
%Other features well classified include marital status, foot pain and number of born children.
%%
The four body size groups could be characterized with an error rate $0.48$, but the decision tree comprises 71 rules and imposes overfitting.

The analysis of the dummy variable yields similar results like the \emph{blood pressure medication}.
%%
Variables, such as subjects sized 139-164 cm, between 64 and 90 years of age or nutrition related parameters are dominantly populated by one manifestation.
%%
The classifier neglects the other group and yields a error rate below $0.5$.
%The dummy variable analysis yields fewer results.
%%
%It shows that subjects between 64 and 90 years of age can be detected with 23\% error rate by using the curvature angle and coronal mean curvature.
%%
%Subjects with body size between 177 cm and 202 cm can classified with an error rate of 22,1\%. solely using mean curvature.
%%
\subsubsection{Gender Groups}
%%
Classification using groups divided by gender do not produce satisfying results.
%%
Only \emph{hypothyroidism} could be described for male subjects with an error rate of $0.24$ for 110 subjects using the \emph{mean curvature} and \emph{curvature angle}.
%%
Since there are only 30 male subjects diagnosed with \emph{hypothyroidism}, the statistical power of the result is reduced.
%%
The dummy variable analysis showed that female subjects of \emph{139-164~cm body size} could be discriminated using the \emph{mean curvature} and \emph{curvature angle}, with an error of $0.38$.

%\com{Potentially skip these due to the confounding of body size}
\subsubsection{Age Groups}
%%
Gender could be classified for each age group using \emph{mean curvature} and \emph{curvature angle}.
%%
The accuracy varies between $0.35$ (\emph{$43.8-54$ years of age}, 3 decision rules) to $0.27$ (\emph{$21-43.8$ years of age}, 6 decision rules).
%%
The starting age of smoking could be characterized well with an error rate between $0.25$ to $0.3$ for all \emph{age} groups except of \emph{$21.1-43.8$ years of age}.
%%
The result however is probably over fitted to the data due to tree sizes between $16$ and $23$.
%%
\com{Feedback der Greifswalder notwendig, warum das so sein koennte.}
%%

Many variables, such as \emph{body size} can be described with an error rate of $0.35$ to $0.45$ but only using large decision trees with over 20 rules.
%Body-size can be determined with an error rate of $0,36$ to $0,39$ for subject
% age groups, but also imposes over fitting to the data yielding a decision tree of over 30 rules.
%%
Notable is also the increasing accuracy with increasing decision tree size.
%%
For subjects between \emph{$43.8-54$ years of age}, the classifier discriminated subjects with thyroid nodules with an error rate of $0.32$.

The dummy variable analysis shows many results using a decision tree with one rule based on \emph{mean curvature} with accuracy between $0.4$ and $0.5$.
%%
It shows that mean curvature can be used to predict dependencies to variables, such as \emph{high blood pressure}, \emph{hypothyroidism} or \emph{nutrition}.

\subsubsection{Size Groups}
%%
Many previously described results are confounded with subject size.
%%
Differences between \emph{male} and \emph{female} subjects are explained by to the average \emph{body size} difference.
%%
For example, large subjects are already characterized by their rather straight spine.
%
The question is, whether the inter-group spine-variability parameter is enough for predicting other parameter or not.
%%
Dividing subjects into \emph{body size} groups potentially highlights classifications not confounded by \emph{body size}.
%%
\paragraph{Large Decision Trees. }
Back pain-associated variables can be explained for various \emph{size}-groups, but we could not extract universal rules.
%%
Radiating back pain could be described with error rate of $0.39$ using 23 rules for subjects between \emph{$171-177~cm$ body size} using \emph{torsion} and \emph{mean curvature}.
%%
For subjects sized \emph{$177-202~cm$} the accuracy drops to $0.47$ using 20 decision rules.
%%
There are several decision trees for laboratory values, such as \emph{alanine aminotransferase} value (relevant for diagnosis of liver or gallbladder illness) in the blood can be described with an error rate of $0.4$ (\emph{$139-164~cm$}) to $0.36$ (\emph{$164 - 171~cm$}).
%%
Similar values can be observed for \emph{cholesterol} or \emph{age}.
%%
Due to the large decision trees, these results are not usable and impose overfitting to the data.
%%
\paragraph{Small Decision Trees. }
%%
The dummy variables show several variables described using only one decision rule with accuracy between $0.42$ to $0.47$.
%%
Most of these variables have a dominant manifestation and the classifier shows a low detection precision for the second manifestation.
%%
These variables include \emph{nutrition} parameter, \emph{thyroid disorder} and \emph{social problems induced by back pain}.

%The resulting trees consist either only one rule or a rich set of them (>15).
%Either they divide the variables using only one decision rule, or a large set of rules (> 15).

%TODO: Muss das wirklich noch rein?
% \com{Manchmal kann es passieren, dass die Quantile fuer eine Variable gleich sind - z.B. bei Dauer Jahre Schwerarbeit, weil viele Probanden hier eben eine 0 haben. Deswegen kann das Ding nicht in vier Qunatile unterteilt werden, die ersten 3 sind 0. Deswegen wurden nur die einzigartigen Unterscheidungen genommen (statt \emph{quantile(myVar)} wurde \emph{unique(quantile(myVar))} verwendet.)}

\com{Auswertung der Anteile der Parameter an den Ergebnissen (Torsion, Curvature, etc. - welches ist der dominanteste Parameter?)}

\section{\uppercase{Conclusion}}
\label{sec:Conclusion}
\noindent The presented results indicate that the parameters \emph{torsion}, \emph{curvature} and \emph{curvature angle} are not enough to characterize pathological changes in the lumbar spine.
%%
They are well suited to characterize subject gender due to their body size difference using \emph{mean curvature} and \emph{mean curvature angle}.
%%
This is due to the higher curvature of smaller subjects and the significant difference of average \emph{body size} between \emph{males} and \emph{females}.
%%
Gender was characterized well in the analysis of all subjects as well as subjects divided by \emph{age}.

Subjects grouped using \underline{body size} have a similar spine shape and a lower variance.
%%
The remaining information within these groups is not enough to characterize back pain-related variables.
%%
%Certain parameters can be classified in 
For some \emph{body size} groups, certain \emph{nutrition} or \emph{psychological} parameters can be predicted with a comparatively high error rate.
%Certain subgroups, however, can be classified for various size groups, such as nutrition or psychological parameters.
%%

Another observation during the analysis is very large decision trees achieving low error scores.
%%
Their complexity impose overfitting to the data and they are not suitable for extracting universal rules.
%%
\subsection{Proposed Features}
\label{sec:ProposedFeatures}
\begin{figure}[!h]
  %\vspace{-0.2cm}
  \centering
  \includegraphics[width=0.5\textwidth]{figures/proposed-features}
  \caption{
	Proposed features.
	%%
	(a) dented vertebraes are a sign of heavy stress and bone absorption.
	%%
	(b, c) the spine canal shape can be used to characterize scoliosis (curvature sagittal) and lordosis (curvature coronal) as well as the \emph{Cobb-Angles} \cite{Cobb}.
	%%
	(c) Spine canal thickness is associated with herniated disks.
	%%
	}
  \label{fig:proposedFeatures}
\end{figure}
%%
\noindent Pathological deformation of the lumbar spine is usually the last stage and is associated with very strong lower back pain \com{Zitat Frau Hegenscheid fragen}.
%%
We have to capture earlier signs of pathological change in order to derive better predictive models.
%%

A very early sign of pathological deformation is the \emph{bone resorption in the center of a vertebra}.
%%
They change from being block-shaped to be dented in the center (Fig~\ref{fig:proposedFeatures}~a).
%%
This information can be obtained by segmenting the whole vertebra or the top and bottom point if each vertebra center.
%%
Another valuable variable would be the \emph{spine canal thickness} (Fig~\ref{fig:proposedFeatures}~c).
%%
Low spine canal thickness can be an indicator for an impending herniated disk.
%%
Both surface texture of the vertebra and thickness of the spine canal are used to diagnose herniated disks.
%%
The \emph{overall spine canal shape} is also of interested, since scoliosis and lordosis can be characterized more precise by deriving the Cobb angles from this shape (Fig~\ref{fig:proposedFeatures}~b,~c).
%% ------------------------------------
\subsection{Applicability}
%%
Classification methods based on decision trees showed to be useful to assess the discriminative power of a variable set.
%%
Their ability to assess variable combination makes them more powerful than correlation coefficients calculated for each variable.
%%
This advantage comes with a much more complex output, making their results harder to assess and to abstract.
%%
Our method to plot derived metrics and custom tailored error measures proved to be effective.
%%
Huge result spaces could be navigated fast using our brushable visualization.
%%
Therefore the method is applicable not only for deriving information based on image data, but on all potential target variables.
%%

As described in a prior work (\cite{Klemm2014VIS}), the suggestion of potentially interesting features when analyzing a condition is an important aspect of visual analytics in epidemiology.
%%
We can achieve this also using the presented method by trying to describe several (dichotomous) target values with a decision tree constructed from all available data.
%%
This allows both to assess the discriminative power of the data set regarding the target variables, as well as the most important parameters for the classification.
%Except for gender in the age-plot, no variable could be explained with reasonable accuracy for age or body size.

\subsection{Summary and Future Work}
%%
\noindent We showed, that \emph{torsion}, \emph{curvature} and \emph{curvature angle} of the lumbar spine at the presented precision are not enough to characterize lumbar back pain in the SHIP data set.
%%
Our method made it possible to assess their discriminative power, which is largely limited for separating \emph{male} and \emph{female} subjects, \emph{nutrition} variables, as well as different disease indicators.
%%
The C4.5 algorithm showed to be an effective tool for evaluating a set of derived metrics regarding their suitability to classify non-image parameters.
%%
Over-fitting to the data indicated by complex decision trees have to be taken into account into the analysis as well.
%%

In our future work, we will focus on more precise models for extracting measures described in Section~\ref{sec:ProposedFeatures}.
%%
As another focus, we want to include the method into existing visual analytics methods designed for analyzing shape information for epidemiological data \cite{Klemm2014VIS}.
%%

Combining the power of statistical analysis, visual analytics and advanced data mining techniques is essential for analyzing increasingly complex heterogenous population data.
%%
These methods do not aim to replace the traditional epidemiological workflow, but rather intervenes at the weak points of standard statistical methods.

\section*{\uppercase{Acknowledgements}}

\noindent \com{TODO: Marko hinzufuegen} SHIP is part of the Community Medicine Research net of the University of Greifswald, Germany, which is funded by the Federal Ministry of Education and Research (grant no. 03ZIK012), the Ministry of Cultural Affairs as well as the Social Ministry of the Federal State of Mecklenburg-West Pomerania. Whole-body MR imaging was supported by a joint grant from Siemens Healthcare, Erlangen, Germany and the Federal State of Mecklenburg-Vorpommern. The University of Greifswald is a member of the ‘Centre of Knowledge Interchange’ program of the Siemens AG. This work was supported by the DFG Priority Program 1335: Scalable Visual Analytics.


\vfill
\bibliographystyle{style/apalike}
{\small
\bibliography{bibliography}}


\section*{\uppercase{Appendix}}

\noindent If any, the appendix should appear directly after the
references without numbering, and not on a new page. To do so please use the following command:
\textit{$\backslash$section*\{APPENDIX\}}

\vfill
\end{document}