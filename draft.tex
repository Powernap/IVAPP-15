\documentclass[a4paper,twoside]{style/article}

\usepackage{epsfig}
\usepackage{subfigure}
\usepackage{calc}
\usepackage{amssymb}
\usepackage{amstext}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{multicol}
\usepackage{pslatex}
\usepackage{apalike}
\usepackage{style/SCITEPRESS}
\usepackage[small]{caption}

\subfigtopskip=0pt
\subfigcapskip=0pt
\subfigbottomskip=0pt

% My Packages and Commands ---
\usepackage[normalem]{ulem}
\usepackage{xcolor}
\usepackage[]{algorithm2e}
\newcommand{\rem}[1]{\textcolor{red}{\sout{#1}}}
\newcommand{\add}[1]{\textcolor{blue}{\uline{#1}}}
\newcommand{\com}[1]{\textcolor{orange}{\uline{#1}}}
% /My Packages and Commands --

\begin{document}

\title{Insight Into Lumbar Back Pain  \subtitle{What the Lumbar Spine Tells About Your Life} }

\author{\authorname{Paul Klemm\sup{1}, Sylvia Glaßer\sup{1}, Kai Lawonn\sup{1} Henry Völzke\sup{2} and Bernhard Preim\sup{1}}
\affiliation{\sup{1}Department of Simulation and Graphics, University of Magdeburg}
\affiliation{\sup{2}Greifswald}
% TODO: Mailaddy nachtragen
\email{\{paul, sylvia\}@isg.cs.uni-magdeburg.de, voelzke@anderAddy}
}

% TODO: The paper must have at least one keyword. The text must be set to 9-point font size and without the use of bold or italic font style. For more than one keyword, please use a comma as a separator. Keywords must be titlecased.
\keywords{My Keywords in Title Case}

\abstract{The abstract should summarize the contents of the paper and should contain at least 70 and at most 200 words. The text must be set to 9-point font size. Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.}

\onecolumn \maketitle \normalsize \vfill

\section{\uppercase{Introduction}}
\label{sec:Introduction}
Epidemiology is the study of causation of diseases. For this purpose, large population studies, such as the \emph{Study of Health in Pomerania} (SHIP) [??] gather as much information as possible about participants to be assessed towards different diseases.
%%
These information are used to determine risk factors for diseases, help people to improve their lifestyle and their health or to support diagnosis of widespread diseases.
%%
Epidemiological research is strongly hypothesis-driven.
%%
More precisely, observations made by clinicians are translated into hypotheses, which are then statistically evaluated using data variables from epidemiological studies.
%%
As a result, the hypothesis will be accepted or rejected.
%%

%For epidemiological research, cohort studies are acquired.
For epidemiological research, cohort studies are carried out.
%%
These studies often comprise medical image data, e.g., tomographic image data sets, as well as general patient-specific attributes like gender, age and weight.
%%
Back pain is one of the most frequent diseases in the western civilization. 
%%
Epidemiological analysis of back pain aim to characterize the disease by determining risk factors.
%Many epidemiological-motivated approaches aim at improved characterization of this disease with respect to patient-specific attributes.
%Since back pain is one of the most frequent diseases in the western civilization, many epidemiological-motivated approaches aim at improved characterization of this disease with respect to patient-specific attributes.
%%
Although the shape and constitution of the spine, especially the lumbar spine, plays an important role for the presence of back pain, no automatic classification approach to characterize back pain based on lumbar back spine attributes has been established yet.
%%
Furthermore, previous analyses mainly focused on a single parameter or a small subset of parameters [Quelle].
%%

In this paper, we present a thorough analysis of the image-derived data from lumbar back spine datasets and analyze their discriminating power for different characteristics of the disease.
%%
Therefore, we combine data mining algorithms with data visualization techniques.
%%
%Then, interactive visual analysis provides insight into the quality of the image-derived data as well as their potential for possible back pain risk factors.
Then, interactive visual analysis provides insight into the quality of the image-derived data as well as their potential for being back pain risk factors.
%%
\com{Da in der Auflistung oefter vom IVA-Framework die Rede ist: Wollen wir hierzu noch was schreiben, z.B. dass das im VIS-Paper definiert wurde und was wir darunter verstehen; sowie dass diese Arbeit als Erweiterung dieses Frameworks gedacht ist?}

Our contributions are:
\begin{itemize}
\item An IVA-framework for back pain analysis based on image-derived variables of 2,240 subjects \com{Ist diskutabel, so richtig interaktiv ist es nicht. IVA wurde auch noch nicht vorher definiert.}
%%
\item The identification and evaluation of lumbar spine shape properties for back pain diagnosis
%%
\item Detection of correlations between image-based and socio-demographic as well as medical parameters for an improved hypothesis generation
%%
\item Identification of the most important variables via data mining methods (including a novel semi-quantitative evaluation concept) embedded in our IVA-framework \com{Wieder: IVA wurde noch nicht definiert}
%%
\end{itemize}

% -- Old Introduction
% Epidemiology is the study of causation of diseases.
% %%
% Large population studies, such as the Study of Health in Pomerania (SHIP) \ref{SHIP} gather as much information as possible about participants to be assessed towards different diseases.
% %%
% These information are used to determine risk factors for diseases, helping people to make their lifestyle healthier or helping in diagnosing a disease.
% %%
% Epidemiological research is strongly hypothesis driven.
% %
% Observations made by clinicians are translated into hypothesis, which are then statistically evaluated using data variables from epidemiological studies.
%
% Modern cohort studies often comprise medical image data.
% %%
% \com{Short summary}
% %%
%
% Back pain is one of the most frequent diseases in the western civilization.
% %%
%
% Our goal is to combine data mining algorithm with data visualization to provide insight into the quality of image derived data to analyze if it acts as a risk factor for a disease.
% %\com{Combine Data Mining Algo}
%
% More than 5 variables are rarely analyzed simultaneously.
% %%
% %The variables analyzed simultaneously is limited to
% Our contributions are:
% \begin{itemize}
% 	\item Analyzing back pain using image-derived variables of 2,240 subjects.
% 	\item Assessing the suitability of lumbar spine shape for diagnosing back pain
% 	\item Analyzing correlations between between image-based and socio-demographic as well as medical parameters.
% 	\item Identification of most important variables using data mining methods \com{noch schoen schreiben}
% 	\item semiquantitative Auswertmöglichkeiten werden dem User oft zur verfügung gestellt
% 	\item Techniken sind als Teil des IVA-Frameworkes zu verstehen
% \end{itemize}

\section{\uppercase{Epidemiological Background}}
\label{sec:EpidemiologicalBackground}
%\noindent \com{Background. Epidemiological Workflow, focus on statistical resilience, image data hard to analyze due to the large amount of subjects, poor image quality and lack of methods}.
\noindent Epidemiology is the study of dissemination, causes and results of health-related states and events.
%%
Epidemiological reasoning relies on a strict statistically driven workflow \cite{Fletcher}:
%%
\begin{itemize}
%%
	\item Physicians formulate hypotheses based on observations made in their clinical practice.
%%
	\item To assess a hypothesis, epidemiologists compile a list of variables depicting it.
%%
	\item Statistical methods, such as regression analysis, assess the association of selected variables with the investigated disease.
%%
\end{itemize}
%%
Mutually dependent variables make this analysis challenging.
%%
Many diseases, such as different cancer types, are more likely with increasing age.
%%
When for example analyzing influences of nutrition to prostate cancer, the results need to be age-normalized.
%%
Age acts as an \emph{confounder} for prostate cancer.
%%
These \emph{confounding} variables are often hard to find.
%%
Statistical correlation does not imply causation--epidemiologists need to assess the medical soundness of the statistical results.
%%------------------------------
\subsection{Epidemiological Data}
Epidemiological data can stem from a wide range of studies.
%%
The study type depends on the condition of interest.
%%
Most common are case-control studies, analyzing one specific disease and its influences.
%%
We focus on data from large scale cohort studies.
%%
These studies aim to collect as much data as possible for each subject.
%%
As a result, these data can be analyzed regarding many diseases and conditions.
%%

Epidemiological data is heterogenous and incomplete.
%%
Women-specific question can only be acquired for female subjects, data about a disease treatment only for subjects suffering from this condition.
%%
Therefore, statistical analysis has to take missing data into account.
%%

Epidemiologists acquire data using a wide range of techniques, such as medical examinations, self reported questionnaires or genetic examinations.
%%
This yields a heterogenous information space.
%%
To compare these data, information reduction techniques are applied.
%%
For example, continuous data, such as age is often discretized into age-bins.
%%
Every information reduction can introduce a bias to the data, since it reflects an assumption about the data.
%%
Using age to divide subjects into \emph{young} and \emph{old} categories can distort statistical results.
%%
This distortion is reduced with increasing number of discretization steps.
%%

Modern cohort studies often comprise medical image data.
%%
These data are hard to analyze, since segmentation algorithms are not generally available and need to be custom-made for each body structure.
%%
Segmentation data is usually analyzed by abstracting it into key figures, such as diameters or distances.
%%
These numeric values can be compared with non-image variables to retrieve correlations.
%%--------------------------------
\subsection{Lower Back Pain}
%%
The lower (\emph{lumbar}) spine is the most stressed part of the spine.
%%
Lower back pain is one of the most frequent diseases in the western civilization.
%%
Epidemiologists assume associations between lumbar back pain and lifestyle factors.
%%
These include nutrition, sporting activities and body posture at work.
%%
The exact causes as well as particularly vulnerable risk groups are not known.
%%
Potential \emph{confounding} effects are also subject of current research.
%%

Epidemiologists want to characterize the healthy aging process of the spine.
%%
To achieve this, they have to analyze the lumbar spine shape as well as the mentioned lifestyle factors.
%% -------------------------------
\section{\uppercase{Related Work}}
\label{sec:RelatedWork}
\noindent \com{Our own work (VIS, VMV, BVM). Sylvias paper with reference to the methods. \textbf{More information necessary here!}}
\com{From VIS Paper}

ToDo Hier weitermachen
Steenwijk
Turkey (Skeweness-Paper)
Angelelli
Abschließend Uniqueness beschreiben

\paragraph{Visual Analysis of Heterogenous Non-Image Data.}
Zhang et al. \cite{Zhang2012} provide a web-based system for analyzing subject groups with linked views and batch-processing capabilities for categorizing new subject entries into the data set.
%
Their definition of a cohort differs from the understanding of the term in an epidemiological context by denoting every parameter-divided subject group as individual cohort.
%
Due to the short paper length, detail is missing on the data types and their algorithms of identifying similar subjects or whether they employ statistical measures.
%
We employ the idea of adding variables via drag and drop into a canvas area.

Generalized Pairs Plots (\texttt{GPLOM´S}) are an information visualization technique comparing heterogenous variables pairwise using a plot-matrix grouped by type \cite{GPLOMS, Francois2013}.
%
They are useful to gain an overview over numerous variables and their distributions.
%
Histograms, bar charts, scatter plots and heat maps are used to visualize variable combinations with regard to their type.
%
The resulting matrix provides an \emph{overview visualization}, but requires a lot of screen space for many variables (127 in our application scenario).
%
%Brushing, linking and filtering are feasible with \texttt{GPLOMS}, but have limitations such as making only one category brushable at a time.
%
%We applied this technique to our data and it shows promising potential for simultaneously visualizing many different variables. %but does not fit in the scope of this paper.
%
We incorporate the idea of adaptive type-dependent visualizations.
%\add{The inspiration on the chosen visualization techniques stems from this publication.}
%
Dai et al. \cite{Dai2005} explored risk factors by incorporating choropleth maps of epidemiological variables (e.g., mortality rates in a region) with parallel coordinates, bar charts and scatter plots with integrated regression lines.
%
Their findings yielded a \emph{Concept Map}, which linked cancer-related associations via graph edges.
%
While their goal to identify possible risk factors using socio-economic and health data is similar to ours, they focus on iteratively refining defined hypotheses and on geographical data.
%
We employ the use of small multiples for incorporating heterogenous data types for comparability.
%
Chui et al. \cite{Chui2011} visualized associations in time-dependent epidemiological data using time-series plots highlighting risk factor differences in age and gender.
%
%The connection of time series plots with histograms and heat maps allows for fast insight into complex relationships and 
While the work shows how different visualization techniques provide insight into these data sets, it focuses on the time aspect, which is not present for our data.

\paragraph{Prior Work.}
We visualized lumbar spine variabilities based on a semi-automatic shape detection algorithm of 490 participants of the \texttt{SHIP-2} cohort \cite{Klemm2013VMV}.
%
Hierarchical agglomerative clustering divided the population into shape-related groups.
%
As proof of concept, a relation between the size of the segmented shape and the measured size of the subjects was shown.
%
This work focuses on incorporating these derived data as new variables, enabling to include it into the hypothesis validation and generation process.
%
When applying clustering techniques to the non-image data it was found that \texttt{k-Prototypes} and \texttt{DBSCAN} are appropriate, but are strongly dependent on the chosen variables and distance measures \cite{Klemm2014BVM}.
%
Niemann et al. \cite{Niemann2014} presented an interactive data mining tool for the assessment of risk factors of hepatic steatosis, the fatty liver disease.
%
Association rules created by data mining methods can be analyzed interactively with their tool and highlight potentially overlooked variables.

\section{The Lumbar Spine Data Set}
\label{sec:MaterialsAndMethod}
%%
\noindent Our approach allows to analyze many variables simultaneously.
%%
Therefore, epidemiologists compiled the data set with a with a wide range of variables possibly correlating with lumbar back pain.
%%
The data set comprises of 6,753 subjects from two cohorts (4,420 from \texttt{SHIP-Trend-0} and 2,333 from \texttt{SHIP-2}).
%%
%It is an active research area to determine these correlations.
%%

%%
\subsection{Non-Image Data}
%\com{Analysis Using Heterogeneous Correlation}
The variables range from somatometric variables describing body measures to medical examinations, such as laboratory tests as well as lifestyle factors as sport activity or nutrition.

\subsection{Image Data}
\begin{figure}[!h]
  %\vspace{-0.2cm}
  \centering
  \includegraphics[width=0.5\textwidth]{figures/centerline}
  \caption{
	(a) left: Tetrahedron-based finite element model (FEM) of the lumbar spine, capturing the L1-L5 vertebrae as well as the lumbar spine canal.
	%%
	(a) right: FEM aligned to a MRI data set.
	%%
	The purple dashed line represents the centerline, describing the lumbar spine canal with 92 points.
	%%
	(b) Using the Frenet formulas, we extract the weighted sum of curvature and torsion for all 92 points (white dashes).
	%%
	The curvature angle ($\alpha$) is calculated using the top, bottom and middle point.
	%%
	We also extracted the variables for each projection axis which to assess their information gain.
	%(b) Using the Frenet formulas, we extract the curvature, torsion and the curvature angle from the lumbar spine canal center line.
	}
  \label{fig:centerline}
\end{figure}
\com{Image Data}
Four trained technicians acquired the medical image data for each subject in a standardized way using a 1.5~Tesla MRI scanner (Magnetom Avanto; Siemens Medical Solutions, Erlangen, Germany).
%%
The spine protocol consisted of a sagittal T1-weighted turbo-spin-echo sequence ($1.1\times1.1\times4.0~mm$ voxels) and a sagittal T2-weighted turbo-spin-echo sequence ($1.1\times1.1\times4.0~mm$ voxels) \cite{Hegenscheid2013}.
%%

A hierarchical finite element method was used to detect the lumbar spine in the MRI data \cite{Rak2013}.
%%
The tetrahedron-based finite element model is initialized using three user-placed land marks.
%%
A click on the L3 vertebra center gives the model the initial position, two clicks on the top and bottom of the vertebra describes an initial model height estimation.
%%
The registered model captures information about the lumbar spine canal shape and the position of the L1-L5 vertebrae \cite{Klemm2013VMV} (Fig.~\ref{fig:centerline}~a).
%%
The detection fails for several subjects due imprecise initialization, imaging artifacts or strongly deformed spines.
%%
$2,540$ lumbar spine models were obtained and constitute the foundation of this work.
%%
%%
% \com{From VIS'14 Paper}
% The lumbar spine was detected in the image data using a hierarchical finite element method by Rak et al. [32].
% %%
% This semiautomatic method requires the user to initialize the tetrahedron-based finite element models (FEM) with a click on the L3 vertebra.
% %%
% Two user-defined landmarks on the top and bottom of the L3 vertebra describe an initial model height estimation.
% %%
% The model uses a weighted sum of T1 and T2-weighted MR images to detect the lumbar spine shape.
% %%
% Once registered, it captures information about the shape of the lumbar spine canal as well as the position of the L1-L5 vertebrae [21].
% %%
% Due to incorrect initialization, strongly deformed spines, contrast differences and artifacts, the model was not able to detect lumbar spines for all subjects.
% %%
% We obtained and worked with 2,540 tetrahedron models of the lumbar spine.
% %%
% For clustering, we extracted the centerline of the lumbar spine canal, which captures information about lordosis and scoliosis (the medical terms for spine curvature) [21].
% %%

We have to assess the model accuracy to extract key figures from it.
%%
The detection model depicts the vertebrae positions, but lacks detailed information about their volume.
%%
It captures reliable information about spine canal curvature.
%%
In a previous work \cite{Klemm2013VMV,Klemm2014VIS}, we extracted a centerline representation of the lumbar spine canal from the detection model (Fig.~\ref{fig:centerline}~a).
%%
Using the Frenet formulas \cite{Frenet}, we extracted the following metrics from the model (Fig.~\ref{fig:centerline}~b):
%%
%Thus, we extracted the following metrics from the model:
%%
%\paragraph{Curvature}
\begin{itemize}
	% \item The curvature of the centerline is calculated using the summed mean curvature between adjacent points:
% %%
% $\sum \frac{curvature_i}{curvature_all}$.
	\item \emph{Curvature} is calculated as weighted sum of curvature between all adjacent points describing the centerline: $\sum \frac{curvature_i}{curvature_{all}}$.
%%
	\item \emph{Torsion} (deviation of a curve from its current course) is calculated as weighted sum of torsion between all adjacent points describing the centerline: $\sum \frac{torsion_i}{torsion_{all}}$.
	\item \emph{Curvature angle $\alpha$} is defined by the middle point of the spine canal centerline as \emph{vertex} and the line between middle point and top/bottom point as \emph{sides}.
%%
\end{itemize}
%%
These figures are also extracted in the sagittal, coronal and transversal projection of the model.
%%
We assess the information gain of each dimension using these projections.
%%
This gives us a total of 9 image-derived parameters.

%\subsection{Creating a Decision Tree using C5.0}
%\com{C4.5 Algorithm for creating decision trees; }

%\subsection{Parameter Assessment}
%Based on first results

\section{\uppercase{Experiments}}
\label{sec:Experiments}
\begin{figure}[!h]
  %\vspace{-0.2cm}
  \centering
  \includegraphics[width=0.5\textwidth]{figures/age-gender}
  \caption{
	%%
	Correlation of age and gender regarding the lumbar spine size.
	%%
	The bar chart shows subjects divided into four different age groups (x-axis) and their subject number (y-axis).
	%%
	Each bar contains the mean lumbar spine of the respective group.
	%%
	The shape color encodes the distance to the overall male (top chart) or female (bottom chart) mean shape.
	%%
	The dark gray share of each bar encodes the portion of male (top chart) or female (bottom chart) subjects.
	%%
	Women have a higher live expectance than men, hence their higher share in the old age group.
	%%
	Also, women are on average smaller than men, hence the larger shape similarity with older subjects.
	%%
	Due to bone erosion, older people are also smaller on average.
	}
  \label{fig:age-gender}
\end{figure}
\noindent Spine shape is confounded by several somatometric variables.
%%
Larger people have also a longer spine and its shape is more straight compared to smaller subjects.
%%
Since men are on average taller than women and people of old age shrink due to bone erosion, gender and age are also confounder (Fig.~\ref{fig:age-gender}).
%%
Large body weight increases the spine load, resulting in a bend shape.
%%
All these variables need to be taken into account, when correlating spine curvature and torsion with non-image parameter.
%%
Since the gender confounder mainly encodes body-height, we decided to divide subjects into body-size groups.
%%
To avoid small outlier groups, epidemiologists recommend using quartiles to discretize metric variables \cite{Klemm2014VIS}.
\subsection{Preliminary Results}
\begin{figure*}[htb]
  %\vspace{-0.2cm}
  \centering
  \includegraphics[width=1.0\textwidth]{figures/image-parameter-range}
  \caption{%%
A generalized pairs plot of all image-derived variables \cite{GPLOMS} colored by presence or absence of back pain.
%%
Pairwise combinations of image-derived variables are visualized using scatter plots left of the matrix diagonal and their correlation with back pain is denoted right of the matrix diagonal.
%%
The box plots (left) and histograms (bottom) display the distribution of each image-variable encoded with back pain.
%%
No correlation with back pain are present can be seen in this plot.
}
  \label{fig:image-parameter-range}
\end{figure*}
%%
\noindent As first experiment we correlated the shape parameter with the binary back pain indicator using a generalized pairs plot \cite{GPLOMS}.
%%
Pairs plots visualize continuous and categorical variables pairwise in a matrix view.
%%
Scatterplots display pairs of continuous variables, bar charts for continuous variable as a function of a categorical variable and box plots pairs of categorical variables.
%%
Since our image-derived variables are metric, their pairwise combinations are visualized using scatterplots.
%%
The combination of the image variables with back pain is visualized as histogram at the left side of the matrix and as box plot on the right side.
%%
Figure~\ref{fig:image-parameter-range} (right) shows the range of each variable as box plot.
%%
The projections to the transversal planes attract attention as they have many outliers.
%%
We conclude that curvature is not as reliable on the transversal plane as it is on the other planes.
%%--------------------------------
\subsubsection{Correlation Matrix}
We calculated an association matrix to to assess correlations between the image parameters.
%%
The pearson correlation coefficients between the numeric variables are depicted right of the matrix diagonal in Figure~\ref{fig:image-parameter-range}.
%%
Curvature, curvature angle and torsion correlate strongly with their planar projections.
%%
Also the mean curvature and the curvature angle correlate by a factor of -0.89.
%%
%Torsion and curvature/curvature angle do not correlate.
Torsion does not correlate with any other image-derived variable.
%%--------------------------------------------------------
\subsubsection{Correlation of Image Parameters With Back Pain}
Figure~\ref{fig:image-parameter-range} shows the distribution of all image-parameters \add{as generalized pairs plot}.
%%
\rem{We created a generalized pairs plot for subject groups derived by dividing them into quantile groups of body-size.}
%%
No statistical significant correlation could be observed through all subject groups.
%%
The box plots show no difference between subjects with and without back pain.

\subsubsection{Assessing the Information Gain Using the PCA}
%%
To determine the information gain per image-derived variables, we calculated a PCA and compared the loadings per dimension.
%%
The first three principal components explain 75\% of variance in the image-derived variables.
%%
The first principal component explains 47\% of the variance and weights primarily \emph{mean curvature}, \emph{curvature sagittal}, \emph{curvature angle} and \emph{curvature angle sagittal}.
%%
The second component, adding 16\% of variance, weigths  \emph{curvature coronal} and \emph{curvature angle coronal}.
%%
The third component explains 12\% of variance and weights \emph{torsion} and \emph{curvature transverse}.
%%
This supports our prior conclusion about the low information gain of the transverse planes.
%%
\emph{Torsion} also adds little variance to the information space.
%% ------------------------------------------
\subsubsection{Heterogenous Correlations}
%%
We then expanded our focus on correlations of image-derived parameters with all other non-image variables.
%%
We applied a heterogenous correlation technique to derive correlations between all variables is the data set.
%%
The method uses the following correlation metrics for the different type combination:
%%
\begin{itemize}
%%
\item \emph{Pearson product-moment} for two continuous variables, 
\item \emph{Polyserial} correlation for one continuous and one categorical variable, and
\item \emph{Polychoric} correlations for two categorical variables.
\end{itemize}
\com{TODO: Abbildung einer Korrelationsmatrix? Waere sehr gross!}
%%
All correlation values are scaled between 0 - no correlation and 1 - identical.
%%
Some variables are too sparse for calculating correlations, for example \emph{treatment of diabetes}, or \emph{medication against high blood pressure}.
%%
We display the resulting \emph{contingency matrix} using a heat map, mapping correlation values to color brightness with white for 0 and dark blue for 1 \cite{Klemm2014VIS}.
%%
We calculated the contingency matrix for all size groups and looked for correlations between image- and non-image derived variables.
%%
The resulting contingency matrices are available as supplementary material and show no strong correlation with any of the parameter.
%%
Only weak correlations could be found for \emph{Mean Curvature} with \emph{gender} (0.42), \emph{body size} (0.39) and \emph{number of born children} (0.29).
%%
One surprising result was the small correlation with \emph{torsion}, which correlated with almost no variables (p values between 0 and 0.05) and \emph{parkinson} (0.24).
%%
This observation brought us to the conclusion to incorporate more sophisticated data mining techniques to assess the influence of the image-derived parameters.

% \subsubsection{Diese Themen hier unterbringen}
% \begin{itemize}
% 	\item Direkter Vergleich
% 	\item Verteilung des Means
% 	\item Korrelationsmatrix
% 	\item PCA
% \end{itemize}
% Weil das nicht ausreichend war, haben wir einen C5.0 Baum erstellt, um alle potentiellen Zusammenhänge zwischen bildbezogenen und Nichtbildbezogenen Parametern herzustellen - Was kann man mit den Bilddaten erklären und was nicht?
%
% HetCor hier noch mit unterbringen. Damit kann man eine Korrelationsmatrix unabhängig vom Datentyp berechnen, um eine große Korrellationsmatrix zu erhalten (Supplementary Material). Hier können die Einträge in den Zeilen der Bildparameter angeschaut werden, um zu schauen, ob man eine Korrellation mit bestimmten Parametern finden kann! Das müsste auch wieder für alle Größengruppen passieren! (https://stats.stackexchange.com/questions/101016/pca-and-component-scores-based-on-a-mix-of-continuous-binary-and-categorical-va)
% Creating a Decision Tree using C5.0

%\com{C4.5 Algorithm for creating decision trees; }

\section{\uppercase{Evaluation of Decision Trees}}
\label{sec:DecisionTrees}
%%
\noindent As described before, correlation coefficients fail to infer back pain status based on lumbar spine canal curvature and torsion.
%%
We rely on predictive classification trained to obtain a complex rule set on how combination of the image-parameter explain non-image variables.
%%
Decision trees are a popular classification method in data mining for creating predictive models.
%%
Leaves of a decision tree represent class labels, branches represent feature conjunctions leading to the class labels.
%%
Decision trees are easy to understand and to read.
%%
They work with numerical as well as categorical data.
%%
This allows epidemiological domain experts to interpret the results without having deep knowledge about the algorithm creating the tree.
%%
Readability is only granted for small trees, complex structures with many branches are not desirable.
%%
Too many branches also impose to the data.
\com{Quelle Decision Tree}

\subsection{The C4.5/C5.0 Algorithm}
Using a trained data set, the C4.5 algorithm builds decision trees based on information entropy.
%%
Such a calculation requires a numeric or categorical target variable.
%%
The algorithm then tries to find a decision tree, which divides the samples using the input variables just like the target variables.
%%
This means, that every node in the tree represents the attribute which splits the data most efficient into the target subset.
%%
The pseudocode for the algorithm is defined in Algorithm~\ref{alg:c4.5} \cite{C4.5Algorithm}.
\begin{algorithm}[]
 Check for base cases\;
 \For{each attribute $a$}{
  Find the normalized information gain ratio from splitting on $a$\;
 }
 Let $a_{best}$ be the attribute with the highest normalized information gain\;
 Create a decision node that splits on $a_{best}$\;
 Recurse on the sublists obtained by splitting on $a_{best}$, and add those nodes as children of node\;
 \caption{Building a decision tree using the C4.5 Algorithm}
 \label{alg:c4.5}
\end{algorithm}
C5.0 is developed to produce smaller decision trees than C4.5 and improve the execution time.
%%
We use the \texttt{R} implementation of C5.0 \cite{c5.0lassification}.
%%
% \begin{enumerate}
% %%
% \item Check for base cases
% %%
% \item For each attribute $a$
% %%
% \begin{enumerate}
% %%
% \item Find the normalized information gain ratio from splitting on $a$
% %%
% \end{enumerate}
% %%
% \item Let $a_{best}$ be the attribute with the highest normalized information gain
% %%
% \item Create a decision node that splits on $a_{best}$
% %%
% \item Recurse on the sublists obtained by splitting on $a_{best}$, and add those nodes as children of node
% %%
% \end{enumerate}
%%
Categorical attributes with more levels are biased with more information gain in a decision tree \cite{deng2011bias}.
%%
Creating dummy variables bypasses this problem.
%%

The actual use for the resulting tree is the classification of new observations (subjects).
%%
Yet, we are interested in the decision rules and the classification accuracy.

\subsection{Interactive Display of Decision Trees}
We have to create a decision tree for every non-image variable to see which one can be explained by image-derived variables.
%%
Since we have 134 non-image variables, the calculation yields a corresponding number of trees.
%%
Dividing the subjects into four groups using body-size, the number increases to 402 trees.
%%
To make the results cognitive feasible, we have to abstract the results of the classification.
%%------------
\subsubsection{Visualization of Classification Results}
\label{subsec:VisualizationOfClassificationResults}
%%
We follow the visual information-seeking mantra and want to provide an overview first, then details-on-demand \ref{shneiderman1996}.
%%
The optimal classification uses a few rules to precisely characterize the target variable.
%%
Therefore, we are interested in \emph{small trees} with a \emph{low classification error rate}.
%%
The two measures form the axis for a \emph{scatter plot} of the classification results.

\paragraph{The Error Term. }
Normally the error rate for a classification is calculated with $error = \frac{classifiedCorrectly_{n}} {n}$ where $n$ is the number of subjects.
%%
The metric usually works well for variables with uniform distribution.
%%
It distorts the result for other distribution types.
%%
If for example a variable indicating a disease is negative for 90\% of the subject and the classifier simply assigns all subjects to \emph{not ill} the error metric would yield an error of 10\%, even though it is very bad.
%%
Our error term therefore incorporates the discriminative power of each manifestation and is denoted as follows:
%%
%Therefore the discriminative power of each dimension in the equation
%error = 1 - \frac{\[ \sum_{m=0}^M \] \frac{M_{classifiedCorrectly}}{M_all}}{number of dimensions}
\begin{equation}
error = 1 - \frac{\sum_{m=0}^M \frac{classifiedCorrectly_{m}}{all_{m}}}{number_{dimensions}}
\end{equation}
$M$ represents the set of manifestation of each variable.
%%
The error is scaled to denote perfect classification with 0 and 1 is equal to random selection.
% The error rate has to be judged depending on the number of classes of the target variable.
% %%
% An error rate of 50\% for a target variable with two manifestations makes the classifier equal to throwing a coin.
% %%
% The same error rate is acceptable a target variable with more than two manifestations.
% %%
% Picking a value for a variable of four manifestations with an error rate of 50\% is better than the random selection (error rate of 75\%).
% %%
% The following scales the error rate so that 0 denotes perfect classification and 1 is equal to random selection.
% %%
% \begin{equation}
% error_{normalized} = \frac{error}{100 - \frac{100}{class number}}
% \end{equation}
%%
It allows for comparability of error rates between variables with different manifestation count.

\paragraph{Attribute Mapping}
The scatter plot axis are defined by tree size and the previously described error metric.
%%
This allows us to visualize a multitude of classification results in one plot.
%%
Lets say we want to classify and compare the same variables for different subject groups, for example male and female subjects.
%%
We can support this by color coding the data points according to group affiliation.

Many follow-up variables are sparse, such as medication of diabetes or reason of early retirement.
%%
The classification algorithm may produce higher accuracy for variables with less subjects due to the small sample size.
%%
This makes these results less reliable.
%%
We removed variables with less than 100 subjects, since they have to few subjects to be statistically significant.
%%
Furthermore, we map the number of subjects associated with a variable to point diameter in the scatter plot.
%%
This allows to instantly assess the reliability of the result.
%%

We apply a square root scale for the tree size axis to highlight data points with few decision rules.
%%
Outlier results with very large decision trees distort otherwise the resulting plot.
%%

%\com{ToDo: SQRT Skalierung der Treesize-Dimension, da hauptsaechlich geringe Groessen von interesse sind, ausreisser aber diesen Bereich schwer durchschaubar machen}
% %%
%
% %%
% Abstracting the classification results into two continuos variables allows us to visualize the result of 134 classifications in one scatter plot.
% %%
% By mapping the group affiliation (in our case body-size) to color or shape, we can even plot all 402 results in a single visualization (Fig.~\ref{fig:decision-tree} a).
%%
\subsubsection{Dummy Variables}
Dummy variables abstract a categorical variable with multiple manifestations into several binary variables.
%%
Each binary variables encodes the presence of a manifestation.
%%
For example, a pain indicator variable ranging from \emph{1 - no pain} to \emph{4 - large pain} is subdivided into four binary variables (\emph{No pain - Yes/No} to \emph{Large Pain - Yes/no}).
%%
One subject can only have one of these variables set to true.
%%
This is useful for our classification, because it allows to determine which manifestation of a variable can be described best using the image data parameter.
%%\com{ToDo: Dummy-Variables}
%%------------
\subsubsection{Interaction With the Visualization}
%%
The described visualization provides a good overview over the classification results.
%%
We however still want to be able to look display \emph{details-on-demand} \ref{shneiderman1996} and examine a decision tree in detail.
%%
This is realized by clicking on a entry on the visualization, which then displays the corresponding decision tree in detail (Fig.~\ref{fig:decision-tree} b).
%%
This allows for sequentially analyzing the classifications.
%%------------
\subsubsection{Implementation}
All analysis are carried out using \texttt{R}, a popular programming language for statistical calculations and visualizations.
%%
The interactive visualizations are realized using the \texttt{ggvis}\footnote{GGVIS Footnote} package.
%%
As opposed to the standard \texttt{R} plots, \texttt{ggvis} allows to adjust visualization parameters using UI controls, such as sliders.
%%
In order to make the train of thought comprehensible, we used \texttt{RMarkdown}, which allows to make reports by combining \texttt{R} with the \texttt{Markdown} syntax.
%%
We used \texttt{R Shiny}\footnote{R Shiny footnote} to make the report available as dynamic web application.
%%
It allows to combine both the ability to create comprehensible reports as well as UI-controls, to adjust visible data and parameters in the plot to allow the viewer to analyze the data.
%%
Furthermore, calculations based on a prior data selection can be redone within the report.
%We implemented our application as web based prototype using \texttt{R Shiny}\footnote{R Shiny footnote} in combination with \texttt{RMarkdown}.
%%
%The package combines the power of \texttt{R} with advantages of web-based applications.
%%
The web-based approach allows us to quickly exchange results with our collaborating epidemiological partners.
%%
They can try out the technique without installing any software.
%%
Exchanging the prototype becomes as easy as exchanging a hyperlink.
%%---------
\subsection{Results}
\begin{figure*}[p!]
  %\vspace{-0.2cm}
  \centering
  \includegraphics[width=0.82\textwidth]{figures/results}
  \caption{
%%
Scatterplot visualization of all C5.0 classification results.
%%
The x-axis shows the number of decisions of the underlying model, the y-axis the classification error rate (see Section~\ref{subsec:VisualizationOfClassificationResults}).
%%
The left scatterplot shows the results for all variables, either metrics expressed via their quantiles, or categorical.
%%
The right scatterplot displays the dummy variables derived from the original variables.
%%
Group affiliation of a data point is color coded:
%%
no group (a), subdivision into male and female subjects (b), quartiles of age (c) and quartiles of body size (d).
%%
%(a) displays all subjects, (b) is divided into male and female subjects, (c) is categorized into quantiles of age and (d) shows the classification of subjects divided by quantiles of body size.
%%
The number of subjects represented in a variable is denoted using the dot diameter.
%%
We only display variables with an error rate below $0,5$, results above this threshold are inaccurate.
%%
A interactive versions of the plot (see supplemental material) makes all data points clickable, showing the corresponding decision tree in a tool tip.
%%
}
  \label{fig:results}
\end{figure*}
We ran the analysis using different subject groups:
\begin{enumerate}
	%%
	\item All subjects,
	%%
	\item subdivision into \emph{male} and \emph{female},
	%%
	\item subdivision into \emph{age quantiles}, yielding the groups (21, 43.8] (43.8, 54] (54, 64] (64, 90],
	%%
	\item subdivision into \emph{size quantiles}, yielding the groups (139, 164], (164, 171], (171, 177], (177, 202].
	%%
\end{enumerate}
We plotted each group twice.
%%
The first plot shows all original variables.
%%
The second plot shows all categorical variables transformed into dichotomous dummy variables.

\subsubsection{All Variables}
%%
The vast majority of parameters can not be described well using the classifier.
%%
This is reflected in the large amount of variables classified with a error rate above $0,6$.
%%
%The first impression of the resulting scatter plots quickly shows a very high amount of variables above an error rate of $0,6$.
%%

% None of the pain indicators can be reliably described using the image-based parameter.
None of the pain indicators can be described reliably using the image-based parameter.
%%
The only variable reliably classified in this group is gender.% with an error rate of 31,5\% using a decision tree of seven rules.
%
It can be discriminated with an error rate of $0,31$ using 7 rules and incorporates only curvature and curvature angle variables.
%
%It mostly incorporates \emph{mean curvature}, \emph{sagittal curvature angle} und sagittal \emph{mean curvature}.
%The perfect categorization of the \emph{dialysis} parameter was conspicuous.
%%
%This is due to the subject distribution among the manifestation.
%%
%Only two subjects receive a dialysis.
%%
%The good discrimination is not meaningful.
%%
Surprisingly high is the classification of medication for high blood pressure.
%%
1,058 subjects are classified with an error rate of $0,47$ solely based on coronal mean curvature.
%%
Almost all subjects who are medicated ($796/1,058$) were correctly classified, the vast majority of non-medicated subjects ($262/1,058$) are false-positive classified.
%%
Therefore the classifier is not as useful as the error-rate would indicate.
%%This is however due to the high amount of people, who are medicated (68\%) and who are almost all correctly class
%%
%Other features well classified include marital status, foot pain and number of born children.
%%
The four body size groups could be characterized with an error rate $0,48$, but the decision tree comprises of 71 rules and imposes overfitting.

The analysis of the dummy variable yields similar results like the blood pressure medication.
%%
Variables, such subjects sized 139-164 cm, between 64 and 90 years of age or nutrition related parameters are dominantly populated by one manifestation.
%%
The classifier neglects the other group and yields a error rate below $0,5$.
%The dummy variable analysis yields fewer results.
%%
%It shows that subjects between 64 and 90 years of age can be detected with 23\% error rate by using the curvature angle and coronal mean curvature.
%%
%Subjects with body size between 177 cm and 202 cm can classified with an error rate of 22,1\%. solely using mean curvature.
%%
\subsubsection{Gender Groups}
%%
Classification using groups divided by gender do not produce satisfying results.
%%
Only hypothyroidism could be described for male subjects with an error rate of $0,24$ for 110 subjects using the \emph{mean curvature} and \emph{curvature angle}.
%%
Since there are only 30 male subjects diagnosed with hypothyroidism, reducing the statistical power of the result.
%%
The dummy variable analysis showed that female subjects of 139-164 cm body height could be discriminated using the mean curvature and curvature angle, with an error of $0,38$.

%\com{Potentially skip these due to the confounding of body size}
\subsubsection{Age Groups}
%%
Gender could be described for each age group using \emph{mean curvature} and \emph{curvature angle}.
%%
The accuracy varies between $0.35$ ($43.8-54$ years of age, 3 decision rules) to $0.27$ ($21-43.8$ years of age, 6 decision rules).
%%
The starting age of smoking could be characterized well with an accuracy between $0.25$ to $0.3$ for all age groups except of $21.1-43.8$ years of age.
%%
The result however is probably over fitted to the data due to tree sizes between $16$ and $23$.
%%
\com{Feedback der Greifswalder notwendig, warum das so sein koennte.}
%%

Many variables, such as body size can be described with an error rate of $0.35$ to $0.45$ but only using large decision trees with over 20 rules.
%Body-size can be determined with an error rate of $0,36$ to $0,39$ for subject
% age groups, but also imposes over fitting to the data yielding a decision tree of over 30 rules.
%%
Notable is also the increasing accuracy with increasing decision tree size.
%%
For subjects between $43.8-54$ years of age, the classifier discriminated subjects with thyroid nodules with an error rate of $0.32$.

The dummy variable analysis shows many results using a decision tree with one rule based on \emph{mean curvature} with accuracy between $0.4$ and $0.5$.
%%
It shows that mean curvature can be used to predict dependencies to variables, such as \emph{high blood pressure}, \emph{hypothyroidism} or \emph{nutrition}.

\subsubsection{Size Groups}
%%
Many previously described results can be associated to be confounded with subject size.
%%
Differences in the gender analysis are mostly due to the average height difference between males and females.
%%
For example, large subjects are already characterized by their rather straight spine.
%
The question is, whether the inter-group spine-variability parameter is enough for predicting other parameter or not.
%%
Dividing subjects into height groups potentially highlights classifications not confounded by body-height.
%%
\paragraph{Large Decision Trees. }
Back-pain associated variables can be explained for various size-groups, but we could not extract universal rules.
%%
Radiating back pain could be described with error rate of $0.39$ using 23 rules for subjects between $171-177~cm$ body size using torsion and mean-curvature.
%%
For subjects sized $177-202~cm$ the accuracy drops to $0.47$ using 20  decision rules.
%%
There are several decision trees for laboratory values, such as alanine aminotransferase value in the blood can be described with a high precision of $0.4$ ($139-164~cm$) to $0.36$ ($164 - 171~cm$).
%%
Similar values can be observed for cholesterol or age.
%%
Due to the large decision trees, these results are not usable and impose overfitting to the data.
%%
\paragraph{Small Decision Trees. }
%%
The dummy variables show several variables described using only one decision rule with accuracy between $0,42$ to $0,47$.
%%
Most of these variables have a dominant manifestation and the classifier shows a low detection precision for the second manifestation.
%%
These variables include nutrition parameter, thyroid disorder and social problems induced by back pain.

%The resulting trees consist either only one rule or a rich set of them (>15).
%Either they divide the variables using only one decision rule, or a large set of rules (> 15).

%TODO: Muss das wirklich noch rein?
% \com{Manchmal kann es passieren, dass die Quantile fuer eine Variable gleich sind - z.B. bei Dauer Jahre Schwerarbeit, weil viele Probanden hier eben eine 0 haben. Deswegen kann das Ding nicht in vier Qunatile unterteilt werden, die ersten 3 sind 0. Deswegen wurden nur die einzigartigen Unterscheidungen genommen (statt \emph{quantile(myVar)} wurde \emph{unique(quantile(myVar))} verwendet.)}

\com{Auswertung der Anteile der Parameter an den Ergebnissen (Torsion, Curvature, etc. - welches ist der dominanteste Parameter?)}

\section{\uppercase{Conclusion}}
\label{sec:Conclusion}
\noindent The presented results indicate that the parameters torsion, curvature and curvature angle are not enough to characterize pathological changes in the lumbar spine.
%%
They are well suited to characterize subject gender due to their height difference using mean curvature and mean curvature angle.
%%
The reason for this lies in the higher curvature of smaller subjects and the significant difference of average body size between males and females.
%%
Gender was characterized well in the analysis of all subjects as well as subjects divided by age.

Subjects grouped using body height have a similar spine shape and a lower variance.
%%
The remaining information within these groups is not enough to characterize back pain related variables.
%%
Certain subgroups, however, can be classified for various size groups, such as nutrition or psychological parameters.
%%

Another observation during the analysis are very large decision trees achieving low error scores.
%%
Their complexity impose overfitting to the data and they are not suitable for extracting universal rules.
%%
\subsection{Proposed Features}
\label{sec:ProposedFeatures}
\begin{figure}[!h]
  %\vspace{-0.2cm}
  \centering
  \includegraphics[width=0.5\textwidth]{figures/proposed-features}
  \caption{
	Proposed features.
	%%
	(a) dented vertebraes are a sign of heavy stress and bone absorption.
	%%
	(b, c) the spine canal shape can be used to characterize scoliosis (curvature sagittal) and lordosis (curvature coronal) as well as the \emph{Cobb-Angles} \cite{Cobb}.
	%%
	(c) Spine canal thickness is associated with herniated disks.
	%%
	}
  \label{fig:proposedFeatures}
\end{figure}
%%
\noindent Pathological deformation of the lumbar spine is usually the last stage and is associated with very strong lower back pain \com{Zitat Frau Hegenscheid fragen}.
%%
We have to capture earlier signs of pathological change in order to derive better predictive models.
%%

A very early sign of pathological deformation is the \emph{bone resorption in the center of a vertebra}.
%%
They change from being block-shaped to be dented in the center (Fig~\ref{fig:proposedFeatures}~a).
%%
This information can be obtained by segmenting the whole vertebra or the top and bottom point if each vertebra center.
%%
Another valuable variable would be the \emph{spine canal thickness} (Fig~\ref{fig:proposedFeatures}~c).
%%
Low spine canal thickness can be an indicator for an impending herniated disk.
%%
Both surface texture of the vertebra and thickness of the spine canal are used to diagnose herniated disks.
%%
The \emph{overall spine canal shape} is also of interested, since scoliosis and lordosis can be characterized more precise by deriving the Cobb angles from this shape (Fig~\ref{fig:proposedFeatures}~b,~c).
%% ------------------------------------
\subsection{Applicability of the Method}
%%
Classification methods based on decision trees showed to be useful to assess the discriminative power of a variable set.
%%
Their ability to assess variable combination makes them more powerful than correlation coefficients calculated for each variable.
%%
This advantage comes with a much more complex output, making their results harder to assess and to abstract.
%%
Our method to plot derived metrics and custom tailored error measures proved to be effective.
%%
Huge result spaces could be navigated fast using our brushable visualization.
%%
Therefore the method is applicable not only for deriving information based on image data, but on all potential target variables.
%%

As described in a prior work \cite{Klemm2014VIS}, the suggestion of potentially interesting features when analyzing a condition is an important aspect of visual analytics in epidemiology.
%%
We can achieve this also using the presented method by trying to describe several (dichotomous) target values with a decision tree constructed from all available data.
%%
This allows both to assess the discriminative power of the data set regarding the target variables, as well as the most important parameters for the classification.
%Except for gender in the age-plot, no variable could be explained with reasonable accuracy for age or body size.

\subsection{Summary and Future Work}
%%
\noindent We showed, that torsion, curvature and curvature angle of the lumbar spine at the presented precision are not enough to characterize lumbar back pain in the SHIP-Data set.
%%
Our method made it possible to assess their discriminative power, which is largely limited for separating male and female subjects, nutrition variables, as well as different disease indicators.
%%
The C4.5 algorithm showed to be an effective tool for evaluating a set of derived metrics regarding their suitability to classify non-image parameters.
%%
Over-fitting to the data indicated by complex decision trees have to be taken into account into the analysis as well.
%%

In our future work, we will focus on more precise models for extracting measures described in Section~\ref{sec:ProposedFeatures}.
%%
As another focus, we want to include the method into existing visual analytics methods designed for analyzing shape information for epidemiological data \cite{Klemm2014VIS}.
%%

Combining the power of statistical analysis, visual analytics and advanced data mining techniques is essential for analyzing increasingly complex heterogenous population data.
%%
These methods do not aim to replace the traditional epidemiological workflow, but rather intervenes at the weak points of standard statistical methods.

\section*{\uppercase{Acknowledgements}}

\noindent SHIP is part of the Community Medicine Research net of the University of Greifswald, Germany, which is funded by the Federal Ministry of Education and Research (grant no. 03ZIK012), the Ministry of Cultural Affairs as well as the Social Ministry of the Federal State of Mecklenburg-West Pomerania. Whole-body MR imaging was supported by a joint grant from Siemens Healthcare, Erlangen, Germany and the Federal State of Mecklenburg-Vorpommern. The University of Greifswald is a member of the ‘Centre of Knowledge Interchange’ program of the Siemens AG. This work was supported by the DFG Priority Program 1335: Scalable Visual Analytics.


\vfill
\bibliographystyle{style/apalike}
{\small
\bibliography{bibliography}}


\section*{\uppercase{Appendix}}

\noindent If any, the appendix should appear directly after the
references without numbering, and not on a new page. To do so please use the following command:
\textit{$\backslash$section*\{APPENDIX\}}

\vfill
\end{document}